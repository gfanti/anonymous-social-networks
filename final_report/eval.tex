\section{Evaluation}

The evaluation of our work is executed on a discrete-event simulator written in Python. This simulator is similar to existing discrete-event simulators such as ns3. Events are put onto a priority queue ordered by time, and executed in a single loop.

This simulator takes in as input different network structures with a list of nodes, links, and node types. Nodes can be either honest or malicious. As mentioned before, we simulate passive adversaries: malicious nodes are honest-but-curious. Whenever a malicious node receives a message, it adds the message, along with the time at which the message is received, to a list of intercepted messages. The timestamp used is the global simulator time, thus we assume that the spies' clocks are roughly synchronized (or that the synchronization time is much smaller than). 
The simulator produces the messages intercepted from malicious nodes.

\subsection{Estimator validation}
We started by attempting to replicate the estimator results in \cite{pinto}. 
In this replication process, we ran into a number of challenges. We encountered four primary mistakes or omissions in \cite{pinto} that affected our estimation accuracy; some of these were easy to correct once we identified them, others were not:
\begin{itemize}
\item There is a typo in equation (2), which describes how to compute the observed delay vector. It should say $[\boldsymbol d]_k=t_{k+1}-t_1$ instead of $[\boldsymbol d]_k=t_{k+1}-t_k$. This is a critical mistake in the description of the estimator that leads to incorrect likelihoods. 
\item Algorithm 2 of the supplemental materials describes how to compute likelihoods for general graphs. In step 6, it should say ``compute the source likelihood using equation (4) for node $s$.", rather than ``using equation (7)." This is because over general graphs, the covariance matrix $\Lambda_s$ is not identical for all nodes, which causes the simplifications in equation (7) to be invalid. As such, the likelihoods should be computed using the more general equation (4). This error initially led to incorrect likelihood computations in our code.
\item Algorithm 2 of the supplemental materials does not explain how to prune graphs that are not tree-structured. Additionally, it does not describe how to incorporate the direction of infection into estimation. These omissions collectively have a significant impact the likelihoods obtained by the algorithm, and we suspect this is partially responsible for our inability to exactly reproduce their results.
\item The parameter specifications of the random graphs in Table 1 are not given. Specifically, the Barabasi-Albert parameter is not given. We therefore tried a range of different parameters.
\end{itemize}

\subsubsection{Trees}
We first tested the estimator on trees. As assumed in \cite{pinto}, each node transmits the message to its neighbors with an iid delay that is distributed according to $\mathcal N(2,0.5)$.
\begin{figure}
\centering
\includegraphics[height = 2.4in]{figures/pd_vs_spies}
\caption{Probability of detection, i.e. $P(\hat v = v^*)$, as a function of the spy probability $p$. This plot was generated over 3-regular trees. Delays $\theta_{ij}$ are modeled as Gaussians $\mathcal N(2,0.5)$, and spreading was run for 8 time units.}
\label{fig:pd_vs_spies}
%\vspace*{-0.4in}
\end{figure}

\begin{figure}
\centering
\includegraphics[height = 2.4in]{figures/hops_vs_spies}
\caption{Hop distance of the estimate $\hat v$ from the true source $v^*$ as a function of the spy probability $p$. This plot was generated over 3-regular trees. Delays $\theta_{ij}$ are modeled as Gaussians $\mathcal N(2,0.5)$, and spreading was run for 8 time units.}
\label{fig:pd_vs_spies}
%\vspace*{-0.4in}
\end{figure}

\subsection{Facebook}

We have found a Facebook dataset \todo{cite} that we plan to use in our simulation, which contains the Facebook links among about 10,000 nodes in 2009. Given a graph, the simulator allows nodes to make decisions about when and how they will spread a message to their neighbors. 
The simulator is implemented as a discrete-time system. Nodes decide to approve messages by drawing samples from a Bernoulli random variable with parameter $0.5$. The network latency is modeled with a geometric random variable with parameter $p$. 
At the start of a simulation run, a certain percentage of the nodes are compromised. We are currently compromising \emph{random} nodes in the network, though we hope to explore different layout of spy nodes. 
At the end of a simulation run, the list of timestamped messages received by malicious nodes are stored in a file and input into estimation algorithms.

We have also implemented a Jordan centrality estimator, which guesses that the true message source is the node with the lowest Jordan centrality. The Jordan centrality of a node is defined as the distance from that node to the farthest node on the graph. In our case, we are finding the node with the minimum distance to the farthest-away spy node in the network. This is the most basic estimator we will test, as it does not even use timing information from the spies. Note that if we were to use this estimator as time tends to infinity, the estimate would always be the same---namely, the most ``central" node in the graph. So we will start by using this estimator at different points in time to infer how the estimate changes over time. We expect the best estimates to occur when the timestamp is small.

Thus far, we have used our simulator to simulate message spreads over Barabasi-Albert graph. However, we have not run our estimation algorithms yet, so we do not know how well the adversary can infer the true message source.

Additionally, we have changed our project definition slightly after realizing that inserting Sybils into the network is equivalent to saying that the legitimate end of Sybil attack edges are spies. Therefore, Sybils do not give any additional information; as such, we can understand the threat that Sybils pose by simply quantifying the proportion of network nodes that befriend Sybils, and treating them as spies. 
